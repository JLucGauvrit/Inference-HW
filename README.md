# Inference FPGA â€” CPU/FPGA Accelerator PoC

This project demonstrates a **Proof of Concept (PoC)** for running Large Language Model (LLM) inference on both **CPU** and **FPGA (ZCU106)**.
It combines C++ inference code, custom HLS kernels, and a Docker-based toolchain to streamline development, build, and deployment.

---

## âœ¨ Features

* **CPU inference**: portable C++17 backend with baseline performance.
* **FPGA acceleration**: custom HLS kernels for transformer operations (MatMul, Softmax, RMSNorm, RoPE, Add, Mul).
* **Dockerized workflow**:

  * UI container (Flask web interface)
  * CPU build container (CMake/g++)
  * FPGA build container (cross-compilation + Vitis)
  * Shared `source/` volume for source code and models
* **SD Image preparation**: bootable PetaLinux image for ZCU106 board.
* **End-to-end reproducibility**: from local dev to on-board execution.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ build-CPU/             # Docker context for CPU builds
â”œâ”€â”€ build-FPGA/            # Docker context for FPGA builds (aarch64 + Vitis)
â”œâ”€â”€ docker-compose.yml     # Multi-container orchestration
â”œâ”€â”€ model/                 # Default model (stories15M.bin, tokenizer.bin)
â”œâ”€â”€ source/                # Shared bind mount (staging area for src/model)
â”œâ”€â”€ src/                   # Inference C++ sources
â”‚   â”œâ”€â”€ main.cpp
â”‚   â”œâ”€â”€ tensor.cpp / .hpp
â”‚   â”œâ”€â”€ context.cpp / .hpp
â”‚   â”œâ”€â”€ decode.cpp / .hpp
â”‚   â”œâ”€â”€ weight.cpp / .hpp
â”‚   â”œâ”€â”€ vocab.cpp / .hpp
â”‚   â”œâ”€â”€ kernel_add.cpp
â”‚   â”œâ”€â”€ kernel_matmul.cpp
â”‚   â”œâ”€â”€ kernel_mul.cpp
â”‚   â”œâ”€â”€ kernel_rmsnorm.cpp
â”‚   â”œâ”€â”€ kernel_rope.cpp
â”‚   â””â”€â”€ kernel_softmax.cpp
â”œâ”€â”€ ui/                    # Web interface (Flask)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ blueprints/
â”‚   â”œâ”€â”€ template/
â”‚   â””â”€â”€ static/
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Requirements

* Docker â‰¥ 28.x with Compose v2
* (Optional) Xilinx Vitis 2025.1 toolchain for FPGA builds
* (Optional) PetaLinux SDK for SD image creation

### 2. Start the environment

```bash
docker compose up --build --watch
```

Open [http://localhost:8080](http://localhost:8080) to access the UI.

### 3. CPU Build

* Go to the **CPU** page in the UI
* Choose:

  * **Base** (use `./src` + `./model`)
  * **Custom** (upload ZIP with your sources/models)
* Trigger a build â†’ output in `./build-CPU/build/`

### 4. FPGA Build

* Stage kernels into `source/src`
* UI triggers the `build-FPGA` container:

  * Compile kernels â†’ `.xo`
  * Link into `binary_container_1.xclbin`
* Transfer artifacts (`.xclbin`, binary) to the ZCU106 board.

### 5. SD Image

* Use the **SD Image** page to generate a bootable PetaLinux image.
* Copy `BOOT.BIN`, `Image`, `system.dtb` to FAT partition.
* Boot board â†’ login via UART/SSH.

---

## ğŸ› ï¸ Manual Build

### CPU (host)

```bash
mkdir build && cd build
cmake -DUSE_CPU_ONLY=ON ..
make -j$(nproc)
```

### FPGA (cross-compile with toolchain)

```bash
cmake -S . -B build_fpga \
  -DCMAKE_TOOLCHAIN_FILE=toolchain-aarch64.cmake \
  -DCMAKE_BUILD_TYPE=Release
cmake --build build_fpga -j
```

Kernels compiled with Vitis:

```bash
v++ -c -t hw --platform zcu106_dpu -k kernel_matmul src/kernel_matmul.cpp -o matmul.xo
v++ -l -t hw --platform zcu106_dpu *.xo -o binary_container_1.xclbin
```

---

## ğŸ“Š Performance

* **CPU** (host): \~23 tok/s
* **FPGA (ZCU106)**: \~8 tok/s (PoC baseline, before kernel optimization)

---

## ğŸ“– Documentation

* Access the documentation site at `/docs` (via the UI)
* Includes: getting started, CPU/FPGA build, SD image, troubleshooting

---

## ğŸ“œ License

[BSD 3-Clause License](LICENSE)




